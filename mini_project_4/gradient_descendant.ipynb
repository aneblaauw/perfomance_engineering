{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import createFromBenchmark, Calculator\n",
    "from math import inf\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from utils import getAllSchedules\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When experimenting with the gradient descendant algorithm, we will use a somewhat large dataset in order to see how the different modifications affects the performance of the algorithm\n",
    "\n",
    "For this experiment we are using the job shop scheduling problem from banchmark_4.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "# Here we are dealing with a somewhat small problem, \n",
    "# this is an ok size for testing the performance for the two different gradient descendant algorithms\n",
    "filename = '/Users/ane/Projects/Performance Engineering/mini_project_4/benchmarks/benchmark_4.txt'\n",
    "problem = createFromBenchmark(filename)\n",
    "all_schedules = getAllSchedules(problem, set_size=3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that the optimal schedule for this problem has a make span of 112 timeunits\n",
    "iterations = 100\n",
    "best = 109\n",
    "calc = Calculator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descendant 1\n",
    "This is the simplest gradient descendant algorithm that starts with one random schedule  and checks the nearest neighbours in order to find the optimal schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 times, best option was found 4 times\n",
      "Average makespan:  185.55\n",
      "Average iterations:  294.21\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "total_makespan1 = 0\n",
    "total_iterations1 = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    best_schedule, makespan, count = calc.gradientDescendant(problem, all_schedules=all_schedules)\n",
    "    total_makespan1 += makespan\n",
    "    total_iterations1 += count\n",
    "    if makespan <= best:\n",
    "        count1 += 1\n",
    "\n",
    "avg_makespan1 = total_makespan1/iterations\n",
    "avg_iterations1 = total_iterations1/iterations\n",
    "print('Out of %s times, best option was found %s times' % (iterations, count1))\n",
    "print('Average makespan: ', avg_makespan1)\n",
    "print('Average iterations: ', avg_iterations1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descendant 2\n",
    "\n",
    "The Gradient Descendant 1 suffers from two drawbacks:\n",
    "– It may end up in a so-called local minimum, i.e. a schedule that it is better that all\n",
    "schedules of its neighborhood, but not globally optimum. A way to fix this problem\n",
    "consists in starting from different initial schedules.\n",
    "– Assume at some point of the descent, the current schedule is σ and that the algorithm\n",
    "picks up a better schedule τ in the neighborhood of σ. Then, σ is in the neighborhood of\n",
    "τ , which means that its score (its total processing time) must be recalculated. An obvious\n",
    "waste of computation resources, that will become even more problematic in Section 2.4.\n",
    "As way to fix this problem consists in memorizing (caching) the schedules for which the\n",
    "calculation of the score has been already performed. Note that this requires to store\n",
    "schedules (and their scores) in a data structure in which insertion and retrieval is efficient.\n",
    "\n",
    "\n",
    "The Gradient Descendant 2 starts from three different inital schedules in order to find the global minimum. The drawback from this is that it will check more schedules and calculate more timespans (which takes time). Hopefully we will save some time because we have memorized already calculated routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations:  100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 8\u001b[0m     best_schedule, makespan, count \u001b[38;5;241m=\u001b[39m \u001b[43mcalc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradientDescendant2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_schedules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_schedules\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     total_makespan2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m makespan\n\u001b[1;32m     10\u001b[0m     total_iterations2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/models/calculator.py:170\u001b[0m, in \u001b[0;36mCalculator.gradientDescendant2\u001b[0;34m(self, problem, set_size, all_schedules)\u001b[0m\n\u001b[1;32m    165\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Step 2\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Schedule 1\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# find the nearest neighbours to this schedule that works, and find the best solution among them\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m best_option, makespan, count \u001b[38;5;241m=\u001b[39m \u001b[43mnearestNeighbour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [best_option, makespan, count]\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Step 3\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#  Repeat for Schedule 2\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# find the nearest neighbours to this schedule that works, and find the best solution among them\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/models/calculator.py:332\u001b[0m, in \u001b[0;36mnearestNeighbour\u001b[0;34m(schedule, archive, problem, calculator)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m calculator\u001b[38;5;241m.\u001b[39mtotalOperationTime(problem, neighbour) \u001b[38;5;241m<\u001b[39m makespan:\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;66;03m# Then this is the better option\u001b[39;00m\n\u001b[1;32m    331\u001b[0m             better_option \u001b[38;5;241m=\u001b[39m neighbour\n\u001b[0;32m--> 332\u001b[0m             makespan \u001b[38;5;241m=\u001b[39m \u001b[43mcalculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotalOperationTime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetter_option\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m             optimal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# the last solution was not optimal\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m'''      \u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    else:\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m        print('Not a possible solution')\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03melse:\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    print('This solution has already been checked, skipping to next neighbour')\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/models/calculator.py:32\u001b[0m, in \u001b[0;36mCalculator.totalOperationTime\u001b[0;34m(self, problem, schedule, case)\u001b[0m\n\u001b[1;32m     29\u001b[0m earliest_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(operation\u001b[38;5;241m.\u001b[39mmachine\u001b[38;5;241m.\u001b[39moperations)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m machine \u001b[38;5;129;01min\u001b[39;00m problem\u001b[38;5;241m.\u001b[39mmachines:\n\u001b[0;32m---> 32\u001b[0m     start, stop \u001b[38;5;241m=\u001b[39m \u001b[43mmachine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLastJob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;241m==\u001b[39m earliest_start:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# does not need to consider the order of the jobs with this id\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/models/machine.py:37\u001b[0m, in \u001b[0;36mMachine.getLastJob\u001b[0;34m(self, job_id)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m:\n\u001b[1;32m     38\u001b[0m         stop \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count2 = 0\n",
    "total_makespan2 = 0\n",
    "total_iterations2 = 0\n",
    "\n",
    "print('Total iterations: ', iterations)\n",
    "for i in range(iterations):\n",
    "    print(i)\n",
    "    best_schedule, makespan, count = calc.gradientDescendant2(problem, all_schedules=all_schedules)\n",
    "    total_makespan2 += makespan\n",
    "    total_iterations2 += count\n",
    "    if makespan <= best:\n",
    "        count2 += 1\n",
    "\n",
    "avg_makespan2 = total_makespan2/iterations\n",
    "avg_iterations2 = total_iterations2/iterations\n",
    "print('Out of %s times, best option was found %s times' % (iterations, count2))\n",
    "print('Average makespan: ', avg_makespan2)\n",
    "print('Average iterations: ', avg_iterations2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the algorithm takes longer to run than the first, but it has a better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descendant 3\n",
    "For this algorithm we are using the Decision Tree Regressor to predict the makespan of a schedule. The reason we are using this method is to avoid calculatibng the total makespan of a schedule that possibly is worse than the best option we have already found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression.ipynb you can see how we ended up choosing this regression model.\n",
    "\n",
    "The dataset we are using to train the algorithm can be found in dataframe_6.csv and consists of about 3000 different possible schedules for the job shop problem from benchmark_4 with the corresponding timespan for each schedule. We decided to save this in a csv  file in order to avoid calculating the timespan for every schedule every time as this takes a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing dataset\n",
    "dataset = pd.read_csv('../mini_project_4/dataframes/dataframe_6.csv')\n",
    "X = dataset.iloc[:, 0:64]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# fit the model\n",
    "tree_regressor = DecisionTreeRegressor(random_state = 0)\n",
    "tree_regressor.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (0, 0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m best_found \u001b[38;5;241m=\u001b[39m inf\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m----> 8\u001b[0m     best_schedule, makespan, count \u001b[38;5;241m=\u001b[39m \u001b[43mcalc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradientDescendant3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_regressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_schedules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_schedules\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     total_makespan3 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m makespan\n\u001b[1;32m     10\u001b[0m     total_iterations3 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/models/calculator.py:223\u001b[0m, in \u001b[0;36mCalculator.gradientDescendant3\u001b[0;34m(self, problem, regression_model, set_size, all_schedules)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_schedules \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# create new all schedules\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     all_schedules \u001b[38;5;241m=\u001b[39m getAllSchedules(problem, set_size)\n\u001b[0;32m--> 223\u001b[0m random_start \u001b[38;5;241m=\u001b[39m \u001b[43mgetRandomSchedules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_schedules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m schedule1 \u001b[38;5;241m=\u001b[39m random_start[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    225\u001b[0m schedule2 \u001b[38;5;241m=\u001b[39m random_start[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Performance Engineering/mini_project_4/utils.py:126\u001b[0m, in \u001b[0;36mgetRandomSchedules\u001b[0;34m(schedules, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m     index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(schedules) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(schedules\u001b[38;5;241m.\u001b[39mpop(index))\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/random.py:248\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/random.py:226\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m istart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(width)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty range for randrange() (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (istart, istop, width))\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m istep \u001b[38;5;241m=\u001b[39m _int(step)\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0, 0, 0)"
     ]
    }
   ],
   "source": [
    "iterations2 = 200\n",
    "count3 = 0\n",
    "total_makespan3 = 0\n",
    "total_iterations3 = 0\n",
    "best_found = inf\n",
    "\n",
    "for i in range(iterations):\n",
    "    best_schedule, makespan, count = calc.gradientDescendant3(problem, tree_regressor, all_schedules=all_schedules)\n",
    "    total_makespan3 += makespan\n",
    "    total_iterations3 += count\n",
    "    if makespan <= best:\n",
    "        count3 += 1\n",
    "    if makespan < best_found:\n",
    "        best_found = makespan\n",
    "\n",
    "avg_makespan3 = total_makespan3/iterations2\n",
    "avg_iterations3 = total_iterations3/iterations2\n",
    "print('Out of %s times, best option was found %s times' % (iterations2, count3))\n",
    "print('Average makespan: ', avg_makespan3)\n",
    "print('Average iterations: ', avg_iterations3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descendant 1\n",
      "Out of 200 times, best option was found 21 times\n",
      "Average makespan:  189.35\n",
      "Average iterations:  304.29\n",
      "\n",
      "Gradient Descendant 2\n",
      "Out of 200 times, best option was found 5 times\n",
      "Average makespan:  144.58\n",
      "Average iterations:  864.09\n",
      "\n",
      "Gradient Descendant 3\n",
      "Out of 200 times, best option was found 0 times\n",
      "Best solution found:  109\n",
      "Average makespan:  157.895\n",
      "Average iterations:  384.37\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Descendant 1')\n",
    "print('Out of %s times, best option was found %s times' % (iterations, count1))\n",
    "print('Average makespan: ', avg_makespan1)\n",
    "print('Average iterations: ', avg_iterations1)\n",
    "\n",
    "print('\\nGradient Descendant 2')\n",
    "print('Out of %s times, best option was found %s times' % (iterations, count2))\n",
    "print('Average makespan: ', avg_makespan2)\n",
    "print('Average iterations: ', avg_iterations2)\n",
    "\n",
    "print('\\nGradient Descendant 3')\n",
    "print('Out of %s times, best option was found %s times' % (iterations2, count3))\n",
    "print('Best solution found: ', best_found)\n",
    "print('Average makespan: ', avg_makespan3)\n",
    "print('Average iterations: ', avg_iterations3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the difference between the three algorithms. By comparing the first and the second gradient descendant algorithm, we see that the second one that start from three different initial states takes a lot longer to find the best schedule, but it also finds better schedules than the first algorithm.\n",
    "\n",
    "By implementing a regression model to guess the score of a schedule without actually computing it we see that the running time for the algorithm has decreased a lot. The results are not as good as the Gradient Descendant 2 algorithm, but at the same time it is much better that the original algorithm.\n",
    "\n",
    "A possible reason why the Gradient Descendant 3 algorithm doesn't find the best solution as often as the Gradient Descendant 2 is because we have not found the optimal regression model to use or that the training dataset for the model is too small. \n",
    "\n",
    "Because the  last algorithm is so quick it is also possible to start from maybe 6 different inital states instead of three without having a worse running time that the Gradient Descendant 2 algorithm."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca150290dc79091d5642c1432564df6210ffd8d684dc0da4ee7ce9bf75211ec1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
